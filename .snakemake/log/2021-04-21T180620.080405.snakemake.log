Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 1 (use --cores to define parallelism)
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	1	all
	4	combine_metrics
	2	make_predictions
	4	plot_prepped_data
	1	prep_io_data
	1	train_model
	13

[Wed Apr 21 18:06:24 2021]
rule prep_io_data:
    input: DRB_data/obs_temp_subset, DRB_data/obs_flow_subset, DRB_data/uncal_sntemp_input_output_subset, DRB_data/distance_matrix_subset.npz
    output: DRB_output/prepped.npz
    jobid: 4
    wildcards: outdir=DRB_output

Terminating processes on user request, this might take some time.
Cancelling snakemake on user request.
